{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16e97fa0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 15\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#     split = x.split(',')\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#     transaction = [x for x in split if x not in ['FNG LARGE CARRY BAG', 'FNG CARRY BAG MEDIUM']]\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     transactions\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[1;32m---> 15\u001b[0m rules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mapriori\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_support\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_confidence\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_lift\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*** Total number of rules formulated: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(rules)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ***\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMarket Basket Analysis Rules\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\apyori.py:287\u001b[0m, in \u001b[0;36mapriori\u001b[1;34m(transactions, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;66;03m# Calculate ordered stats.\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m support_record \u001b[38;5;129;01min\u001b[39;00m support_records:\n\u001b[1;32m--> 287\u001b[0m     ordered_statistics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_filter_ordered_statistics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_gen_ordered_statistics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransaction_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msupport_record\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmin_confidence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_confidence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmin_lift\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_lift\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ordered_statistics:\n\u001b[0;32m    295\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\apyori.py:237\u001b[0m, in \u001b[0;36mfilter_ordered_statistics\u001b[1;34m(ordered_statistics, **kwargs)\u001b[0m\n\u001b[0;32m    234\u001b[0m min_confidence \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_confidence\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0.0\u001b[39m)\n\u001b[0;32m    235\u001b[0m min_lift \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_lift\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0.0\u001b[39m)\n\u001b[1;32m--> 237\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ordered_statistic \u001b[38;5;129;01min\u001b[39;00m ordered_statistics:\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ordered_statistic\u001b[38;5;241m.\u001b[39mconfidence \u001b[38;5;241m<\u001b[39m min_confidence:\n\u001b[0;32m    239\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\apyori.py:218\u001b[0m, in \u001b[0;36mgen_ordered_statistics\u001b[1;34m(transaction_manager, record)\u001b[0m\n\u001b[0;32m    215\u001b[0m items_add \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfrozenset\u001b[39m(items\u001b[38;5;241m.\u001b[39mdifference(items_base))\n\u001b[0;32m    216\u001b[0m confidence \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    217\u001b[0m     record\u001b[38;5;241m.\u001b[39msupport \u001b[38;5;241m/\u001b[39m transaction_manager\u001b[38;5;241m.\u001b[39mcalc_support(items_base))\n\u001b[1;32m--> 218\u001b[0m lift \u001b[38;5;241m=\u001b[39m confidence \u001b[38;5;241m/\u001b[39m \u001b[43mtransaction_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_support\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems_add\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m OrderedStatistic(\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28mfrozenset\u001b[39m(items_base), \u001b[38;5;28mfrozenset\u001b[39m(items_add), confidence, lift)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\apyori.py:88\u001b[0m, in \u001b[0;36mTransactionManager.calc_support\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m     85\u001b[0m         sum_indexes \u001b[38;5;241m=\u001b[39m indexes\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;66;03m# Calculate the intersection on not the first time.\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m         sum_indexes \u001b[38;5;241m=\u001b[39m sum_indexes\u001b[38;5;241m.\u001b[39mintersection(indexes)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# Calculate and return the support.\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mlen\u001b[39m(sum_indexes)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_transaction\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#v2 new data excluding transactions of NA customers.\n",
    "# works better\n",
    "#MP\n",
    "import pandas as pd\n",
    "from apyori import apriori\n",
    "import ast\n",
    "\n",
    "dataset = pd.read_csv('./transactions.csv', header = None)[0].apply(ast.literal_eval)\n",
    "transactions = []\n",
    "for x in dataset:\n",
    "#     split = x.split(',')\n",
    "#     transaction = [x for x in split if x not in ['FNG LARGE CARRY BAG', 'FNG CARRY BAG MEDIUM']]\n",
    "    transactions.append(x)\n",
    "    \n",
    "rules = list(apriori(transactions, min_support = 0.01, min_confidence = 0.7, min_lift = 1.5))\n",
    "\n",
    "\n",
    "print(f\"*** Total number of rules formulated: {len(rules)} ***\")\n",
    "print(\"Market Basket Analysis Rules\", end=\"\\n\\n\")\n",
    "\n",
    "\n",
    "for i in rules:\n",
    "    base_item_set = str(i[2][0].items_base).removeprefix(\"frozenset({\").removesuffix(\"})\")\n",
    "    add_item_set = str(i[2][0].items_add).removeprefix(\"frozenset({\").removesuffix(\"})\")\n",
    "    confidence = f\"{round(i[2][0].confidence * 100,2)}%\"\n",
    "    print(f\"Item set 1: {base_item_set}\\nItem set 2: {add_item_set}\\nconfidence = {confidence}\", end=\"\\n\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8ecb60",
   "metadata": {},
   "source": [
    "# Cleaned FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c803507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_consequents, all_antecedents, all_conf, all_lift = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1e0323b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Total number of rules formulated: 1001 ***\n",
      "*** Total number of strong rules: 7 ***\n",
      "Market Basket Analysis Rules\n",
      "\n",
      "Item set 1: 'COLD & FROZEN FOODS', 'BISCUITS', 'JUICES'\n",
      "Item set 2: 'DAIRY'\n",
      "confidence = 81.86%\n",
      "lift = 1.7\n",
      "\n",
      "Item set 1: 'DISPOSABLES/ PARTY SUPPLIES', 'TOILET BATHROOM CLEANERS'\n",
      "Item set 2: 'FLOOR CLEANERS'\n",
      "confidence = 79.68%\n",
      "lift = 1.84\n",
      "\n",
      "Item set 1: 'NAMKEENS', 'TEA', 'OIL'\n",
      "Item set 2: 'BISCUITS'\n",
      "confidence = 83.03%\n",
      "lift = 3.28\n",
      "\n",
      "Item set 1: 'WHOLE SPICES', 'OIL', 'WHOLE CEREALS'\n",
      "Item set 2: 'DAL&PULSES'\n",
      "confidence = 77.83%\n",
      "lift = 6.1\n",
      "\n",
      "Item set 1: 'DAL&PULSES', 'SUGAR', 'WHOLE CEREALS'\n",
      "Item set 2: 'FLOURS'\n",
      "confidence = 75.5%\n",
      "lift = 4.57\n",
      "\n",
      "Item set 1: 'TEA', 'DAL&PULSES', 'SUGAR'\n",
      "Item set 2: 'OIL'\n",
      "confidence = 70.85%\n",
      "lift = 6.11\n",
      "\n",
      "Item set 1: 'DETERGENTS', 'TEA', 'OIL'\n",
      "Item set 2: 'UTENSIL SOAPS/SCRUBBER'\n",
      "confidence = 70.26%\n",
      "lift = 8.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#v4 Elite customers, Unique consequents, cleaned.\n",
    "#MP\n",
    "import pandas as pd\n",
    "from apyori import apriori\n",
    "import ast\n",
    "\n",
    "dataset = pd.read_csv('./elite_transactions.csv', header = None)[0][1:].apply(ast.literal_eval)\n",
    "transactions = []\n",
    "for x in dataset:\n",
    "    transactions.append(x)\n",
    "rules = list(apriori(transactions, min_support = 0.01, min_confidence = 0.7, min_lift = 1.5))\n",
    "\n",
    "\n",
    "print(f\"*** Total number of rules formulated: {len(rules)} ***\")\n",
    "\n",
    "\n",
    "antecedents, consequents, consequent_conf, consequent_lift = [], [], [], []\n",
    "\n",
    "for i in rules:\n",
    "    base_item_set = str(i[2][0].items_base).removeprefix(\"frozenset({\").removesuffix(\"})\")\n",
    "    add_item_set = str(i[2][0].items_add).removeprefix(\"frozenset({\").removesuffix(\"})\")\n",
    "    confidence = f\"{round(i[2][0].confidence * 100,2)}\"\n",
    "    lift = f\"{round(i[2][0].lift,2)}\"\n",
    "    if add_item_set not in consequents:\n",
    "        antecedents.append(base_item_set)\n",
    "        consequents.append(add_item_set)\n",
    "        consequent_conf.append(float(confidence))\n",
    "        consequent_lift.append(float(lift))\n",
    "        if add_item_set not in all_consequents:\n",
    "            all_antecedents.append(base_item_set)\n",
    "            all_consequents.append(add_item_set)\n",
    "            all_conf.append(float(confidence))\n",
    "            all_lift.append(float(lift))\n",
    "    else:\n",
    "        prev_conf = consequent_conf[consequents.index(add_item_set)]\n",
    "        if(float(confidence) > prev_conf):\n",
    "            antecedents[consequents.index(add_item_set)] = base_item_set\n",
    "            all_antecedents[consequents.index(add_item_set)] = base_item_set\n",
    "            consequent_conf[consequents.index(add_item_set)] = float(confidence)\n",
    "            all_conf[consequents.index(add_item_set)] = float(confidence)\n",
    "            consequent_lift[consequents.index(add_item_set)] = float(lift)\n",
    "            all_lift[consequents.index(add_item_set)] = float(lift)\n",
    "print(f\"*** Total number of strong rules: {len(consequents)} ***\")\n",
    "print(\"Market Basket Analysis Rules\", end=\"\\n\\n\")\n",
    "for i in range(len(consequents)):\n",
    "    print(f\"Item set 1: {antecedents[i]}\\nItem set 2: {consequents[i]}\\nconfidence = {consequent_conf[i]}%\\nlift = {consequent_lift[i]}\", end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4baac698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Total number of rules formulated: 18 ***\n",
      "*** Total number of strong rules: 3 ***\n",
      "Market Basket Analysis Rules\n",
      "\n",
      "Item set 1: 'INSTANT SNACKS', 'TEA'\n",
      "Item set 2: 'BISCUITS'\n",
      "confidence = 72.73%\n",
      "lift = 3.33\n",
      "\n",
      "Item set 1: 'INSTANT SNACKS', 'FLOOR CLEANERS', 'BAKERY ITEMS', 'NAMKEENS'\n",
      "Item set 2: 'DAIRY'\n",
      "confidence = 75.59%\n",
      "lift = 1.86\n",
      "\n",
      "Item set 1: 'INSTANT SNACKS', 'DISPOSABLES/ PARTY SUPPLIES'\n",
      "Item set 2: 'FLOOR CLEANERS'\n",
      "confidence = 70.45%\n",
      "lift = 1.94\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#v4 Moderate value customers, Unique consequents, cleaned.\n",
    "#MP\n",
    "import pandas as pd\n",
    "from apyori import apriori\n",
    "import ast\n",
    "\n",
    "dataset = pd.read_csv('./moderate_transactions.csv', header = None)[0][1:].apply(ast.literal_eval)\n",
    "transactions = []\n",
    "for x in dataset:\n",
    "    transactions.append(x)\n",
    "rules = list(apriori(transactions, min_support = 0.01, min_confidence = 0.7, min_lift = 1.5))\n",
    "\n",
    "\n",
    "print(f\"*** Total number of rules formulated: {len(rules)} ***\")\n",
    "\n",
    "\n",
    "antecedents, consequents, consequent_conf, consequent_lift = [], [], [], []\n",
    "\n",
    "for i in rules:\n",
    "    base_item_set = str(i[2][0].items_base).removeprefix(\"frozenset({\").removesuffix(\"})\")\n",
    "    add_item_set = str(i[2][0].items_add).removeprefix(\"frozenset({\").removesuffix(\"})\")\n",
    "    confidence = f\"{round(i[2][0].confidence * 100,2)}\"\n",
    "    lift = f\"{round(i[2][0].lift,2)}\"\n",
    "    if add_item_set not in consequents:\n",
    "        antecedents.append(base_item_set)\n",
    "        consequents.append(add_item_set)\n",
    "        consequent_conf.append(float(confidence))\n",
    "        consequent_lift.append(float(lift))\n",
    "        if add_item_set not in all_consequents:\n",
    "            all_antecedents.append(base_item_set)\n",
    "            all_consequents.append(add_item_set)\n",
    "            all_conf.append(float(confidence))\n",
    "            all_lift.append(float(lift))\n",
    "    else:\n",
    "        prev_conf = consequent_conf[consequents.index(add_item_set)]\n",
    "        if(float(confidence) > prev_conf):\n",
    "            antecedents[consequents.index(add_item_set)] = base_item_set\n",
    "            all_antecedents[consequents.index(add_item_set)] = base_item_set\n",
    "            consequent_conf[consequents.index(add_item_set)] = float(confidence)\n",
    "            all_conf[consequents.index(add_item_set)] = float(confidence)\n",
    "            consequent_lift[consequents.index(add_item_set)] = float(lift)\n",
    "            all_lift[consequents.index(add_item_set)] = float(lift)\n",
    "print(f\"*** Total number of strong rules: {len(consequents)} ***\")\n",
    "print(\"Market Basket Analysis Rules\", end=\"\\n\\n\")\n",
    "for i in range(len(consequents)):\n",
    "    print(f\"Item set 1: {antecedents[i]}\\nItem set 2: {consequents[i]}\\nconfidence = {consequent_conf[i]}%\\nlift = {consequent_lift[i]}\", end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6ff2d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Total number of rules formulated: 287 ***\n",
      "*** Total number of strong rules: 13 ***\n",
      "Market Basket Analysis Rules\n",
      "\n",
      "Item set 1: 'BREAKFAST CEREALS', 'OIL'\n",
      "Item set 2: 'FLOOR CLEANERS'\n",
      "confidence = 100.0%\n",
      "lift = 2.33\n",
      "\n",
      "Item set 1: 'CHIPS', 'COFFEE'\n",
      "Item set 2: 'DAIRY'\n",
      "confidence = 90.0%\n",
      "lift = 2.14\n",
      "\n",
      "Item set 1: 'COLD & FROZEN FOODS', 'CARBONATED', 'BISCUITS'\n",
      "Item set 2: 'BAKERY ITEMS'\n",
      "confidence = 78.95%\n",
      "lift = 2.6\n",
      "\n",
      "Item set 1: 'CHIPS', 'INSTANT SNACKS', 'INSTANT MEALS'\n",
      "Item set 2: 'BISCUITS'\n",
      "confidence = 100.0%\n",
      "lift = 4.4\n",
      "\n",
      "Item set 1: 'SPICES OTHERS', 'FLOOR CLEANERS', 'BISCUITS'\n",
      "Item set 2: 'NAMKEENS'\n",
      "confidence = 83.33%\n",
      "lift = 3.42\n",
      "\n",
      "Item set 1: 'INSTANT MEALS', 'CONFECTIONERY'\n",
      "Item set 2: 'INSTANT SNACKS'\n",
      "confidence = 76.19%\n",
      "lift = 4.35\n",
      "\n",
      "Item set 1: 'MASALA & GROUND SPICE  POWDER', 'RICE', 'DAL&PULSES'\n",
      "Item set 2: 'FLOURS'\n",
      "confidence = 100.0%\n",
      "lift = 7.59\n",
      "\n",
      "Item set 1: 'FLOURS', 'BISCUITS', 'WHOLE CEREALS'\n",
      "Item set 2: 'DAL&PULSES'\n",
      "confidence = 78.95%\n",
      "lift = 7.14\n",
      "\n",
      "Item set 1: 'MASALA & GROUND SPICE  POWDER', 'FLOURS', 'SALT'\n",
      "Item set 2: 'OIL'\n",
      "confidence = 88.89%\n",
      "lift = 9.12\n",
      "\n",
      "Item set 1: 'MASALA & GROUND SPICE  POWDER', 'OIL', 'SALT'\n",
      "Item set 2: 'WHOLE SPICES'\n",
      "confidence = 88.24%\n",
      "lift = 8.99\n",
      "\n",
      "Item set 1: 'FLOOR CLEANERS', 'FLOURS', 'SALT'\n",
      "Item set 2: 'UPWAS MAIN ITEMS'\n",
      "confidence = 72.73%\n",
      "lift = 10.19\n",
      "\n",
      "Item set 1: 'MASALA & GROUND SPICE  POWDER', 'SALT'\n",
      "Item set 2: 'WHOLE SPICES', 'FLOURS'\n",
      "confidence = 70.83%\n",
      "lift = 19.11\n",
      "\n",
      "Item set 1: 'MASALA & GROUND SPICE  POWDER', 'FLOURS', 'SALT'\n",
      "Item set 2: 'WHOLE SPICES', 'OIL'\n",
      "confidence = 83.33%\n",
      "lift = 25.83\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#v4 Cost Conscious customers, Unique consequents, cleaned.\n",
    "#MP\n",
    "import pandas as pd\n",
    "from apyori import apriori\n",
    "import ast\n",
    "\n",
    "dataset = pd.read_csv('./cotcon_transactions.csv', header = None)[0][1:].apply(ast.literal_eval)\n",
    "transactions = []\n",
    "for x in dataset:\n",
    "    transactions.append(x)\n",
    "rules = list(apriori(transactions, min_support = 0.01, min_confidence = 0.7, min_lift = 1.5))\n",
    "\n",
    "\n",
    "print(f\"*** Total number of rules formulated: {len(rules)} ***\")\n",
    "\n",
    "\n",
    "antecedents, consequents, consequent_conf, consequent_lift = [], [], [], []\n",
    "\n",
    "for i in rules:\n",
    "    base_item_set = str(i[2][0].items_base).removeprefix(\"frozenset({\").removesuffix(\"})\")\n",
    "    add_item_set = str(i[2][0].items_add).removeprefix(\"frozenset({\").removesuffix(\"})\")\n",
    "    confidence = f\"{round(i[2][0].confidence * 100,2)}\"\n",
    "    lift = f\"{round(i[2][0].lift,2)}\"\n",
    "    if add_item_set not in consequents:\n",
    "        antecedents.append(base_item_set)\n",
    "        consequents.append(add_item_set)\n",
    "        consequent_conf.append(float(confidence))\n",
    "        consequent_lift.append(float(lift))\n",
    "        if add_item_set not in all_consequents:\n",
    "            all_antecedents.append(base_item_set)\n",
    "            all_consequents.append(add_item_set)\n",
    "            all_conf.append(float(confidence))\n",
    "            all_lift.append(float(lift))\n",
    "    else:\n",
    "        prev_conf = consequent_conf[consequents.index(add_item_set)]\n",
    "        if(float(confidence) > prev_conf):\n",
    "            antecedents[consequents.index(add_item_set)] = base_item_set\n",
    "            all_antecedents[consequents.index(add_item_set)] = base_item_set\n",
    "            consequent_conf[consequents.index(add_item_set)] = float(confidence)\n",
    "            all_conf[consequents.index(add_item_set)] = float(confidence)\n",
    "            consequent_lift[consequents.index(add_item_set)] = float(lift)\n",
    "            all_lift[consequents.index(add_item_set)] = float(lift)\n",
    "print(f\"*** Total number of strong rules: {len(consequents)} ***\")\n",
    "print(\"Market Basket Analysis Rules\", end=\"\\n\\n\")\n",
    "for i in range(len(consequents)):\n",
    "    print(f\"Item set 1: {antecedents[i]}\\nItem set 2: {consequents[i]}\\nconfidence = {consequent_conf[i]}%\\nlift = {consequent_lift[i]}\", end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1510236e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Total number of rules formulated: 136 ***\n",
      "*** Total number of strong rules: 6 ***\n",
      "Market Basket Analysis Rules\n",
      "\n",
      "Item set 1: 'INSTANT SNACKS', 'DETERGENTS'\n",
      "Item set 2: 'BAKERY ITEMS'\n",
      "confidence = 81.08%\n",
      "lift = 2.0\n",
      "\n",
      "Item set 1: 'BATH SOAP & BODYWASH', 'FLOURS'\n",
      "Item set 2: 'BISCUITS'\n",
      "confidence = 88.57%\n",
      "lift = 2.6\n",
      "\n",
      "Item set 1: 'BAKERY ITEMS', 'BATH SOAP & BODYWASH'\n",
      "Item set 2: 'FLOOR CLEANERS'\n",
      "confidence = 94.59%\n",
      "lift = 1.95\n",
      "\n",
      "Item set 1: 'CARBONATED', 'JUICES'\n",
      "Item set 2: 'DAIRY'\n",
      "confidence = 81.08%\n",
      "lift = 2.06\n",
      "\n",
      "Item set 1: 'BATH SOAP & BODYWASH', 'FLOURS'\n",
      "Item set 2: 'FLOOR CLEANERS', 'BISCUITS'\n",
      "confidence = 82.86%\n",
      "lift = 3.97\n",
      "\n",
      "Item set 1: 'BAKERY ITEMS', 'DAL&PULSES', 'BISCUITS'\n",
      "Item set 2: 'FLOURS'\n",
      "confidence = 73.33%\n",
      "lift = 3.85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#v4 Frequent customers, Unique consequents, cleaned.\n",
    "#MP\n",
    "import pandas as pd\n",
    "from apyori import apriori\n",
    "import ast\n",
    "\n",
    "dataset = pd.read_csv('./freq_transactions.csv', header = None)[0][1:].apply(ast.literal_eval)\n",
    "transactions = []\n",
    "for x in dataset:\n",
    "    transactions.append(x)\n",
    "rules = list(apriori(transactions, min_support = 0.03, min_confidence = 0.7, min_lift = 1.5))\n",
    "\n",
    "\n",
    "print(f\"*** Total number of rules formulated: {len(rules)} ***\")\n",
    "\n",
    "\n",
    "antecedents, consequents, consequent_conf, consequent_lift = [], [], [], []\n",
    "\n",
    "for i in rules:\n",
    "    base_item_set = str(i[2][0].items_base).removeprefix(\"frozenset({\").removesuffix(\"})\")\n",
    "    add_item_set = str(i[2][0].items_add).removeprefix(\"frozenset({\").removesuffix(\"})\")\n",
    "    confidence = f\"{round(i[2][0].confidence * 100,2)}\"\n",
    "    lift = f\"{round(i[2][0].lift,2)}\"\n",
    "    if add_item_set not in consequents:\n",
    "        antecedents.append(base_item_set)\n",
    "        consequents.append(add_item_set)\n",
    "        consequent_conf.append(float(confidence))\n",
    "        consequent_lift.append(float(lift))\n",
    "        if add_item_set not in all_consequents:\n",
    "            all_antecedents.append(base_item_set)\n",
    "            all_consequents.append(add_item_set)\n",
    "            all_conf.append(float(confidence))\n",
    "            all_lift.append(float(lift))\n",
    "    else:\n",
    "        prev_conf = consequent_conf[consequents.index(add_item_set)]\n",
    "        if(float(confidence) > prev_conf):\n",
    "            antecedents[consequents.index(add_item_set)] = base_item_set\n",
    "            all_antecedents[consequents.index(add_item_set)] = base_item_set\n",
    "            consequent_conf[consequents.index(add_item_set)] = float(confidence)\n",
    "            all_conf[consequents.index(add_item_set)] = float(confidence)\n",
    "            consequent_lift[consequents.index(add_item_set)] = float(lift)\n",
    "            all_lift[consequents.index(add_item_set)] = float(lift)\n",
    "print(f\"*** Total number of strong rules: {len(consequents)} ***\")\n",
    "print(\"Market Basket Analysis Rules\", end=\"\\n\\n\")\n",
    "for i in range(len(consequents)):\n",
    "    print(f\"Item set 1: {antecedents[i]}\\nItem set 2: {consequents[i]}\\nconfidence = {consequent_conf[i]}%\\nlift = {consequent_lift[i]}\", end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "034769d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 'BISCUITS'  'FLOURS'  'OIL' 'BAKERY ITEMS' 'BISCUITS' 'DAIRY' 'DAL&PULSES' 'FLOOR CLEANERS' 'FLOURS' 'INSTANT SNACKS' 'NAMKEENS' 'OIL' 'UPWAS MAIN ITEMS' 'UTENSIL SOAPS/SCRUBBER' 'WHOLE SPICES' "
     ]
    }
   ],
   "source": [
    "new_all_consequents= []\n",
    "for x in all_consequents:\n",
    "    split = x.split()\n",
    "    if len(split) == 1 and x not in new_all_consequents:\n",
    "        new_all_consequents.append(x)\n",
    "    else:\n",
    "        for y in x.split(','):\n",
    "            if y not in new_all_consequents:\n",
    "                new_all_consequents.append(y)\n",
    "\n",
    "for x in sorted(new_all_consequents):\n",
    "    print(x,end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d1bb027",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_conv = []\n",
    "for i in range(len(all_consequents)):\n",
    "    antecedent = all_antecedents[i]\n",
    "    consequent = all_consequents[i]\n",
    "    confidence_ = all_conf[i]\n",
    "    lift_ = all_lift[i]\n",
    "    tran = [antecedent, consequent, confidence_, lift_]\n",
    "    csv_conv.append(tran)\n",
    "csv_conv\n",
    "df = pd.DataFrame(csv_conv, columns=['Antecedent', 'Consequent', 'Confidence','Lift'])\n",
    "df.to_csv('all_rules.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
